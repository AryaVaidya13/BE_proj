[
  {
    "title": "A Multi-AI Agent System for Autonomous Optimization of Agentic AI Solutions via Iterative Refinement and LLM-Driven Feedback Loops",
    "abstract": "Agentic AI systems use specialized agents to handle tasks within complex workflows, enabling automation and efficiency. However, optimizing these systems often requires labor-intensive, manual adjustments to refine roles, tasks, and interactions. This paper introduces a framework for autonomously optimizing Agentic AI solutions across industries, such as NLP-driven enterprise applications. The system employs agents for Refinement, Execution, Evaluation, Modification, and Documentation, leveraging iterative feedback loops powered by an LLM (Llama 3.2-3B). The framework achieves optimal performance without human input by autonomously generating and testing hypotheses to improve system configurations. This approach enhances scalability and adaptability, offering a robust solution for real-world applications in dynamic environments. Case studies across diverse domains illustrate the transformative impact of this framework, showcasing significant improvements in output quality, relevance, and actionability. All data for these case studies, including original and evolved agent codes, along with their outputs, are here: https://anonymous.4open.science/r/evolver-1D11/",
    "authors": [
      "K. Yuksel",
      "H. Sawaf"
    ],
    "year": 2024,
    "url": "https://www.semanticscholar.org/paper/417b37838b58d0cf790cd572605662559d5c1dc6"
  },
  {
    "title": "Hallucination Mitigation using Agentic AI Natural Language-Based Frameworks",
    "abstract": "Hallucinations remain a significant challenge in current Generative AI models, undermining trust in AI systems and their reliability. This study investigates how orchestrating multiple specialized Artificial Intelligent Agents can help mitigate such hallucinations, with a focus on systems leveraging Natural Language Processing (NLP) to facilitate seamless agent interactions. To achieve this, we design a pipeline that introduces over three hundred prompts, purposefully crafted to induce hallucinations, into a front-end agent. The outputs are then systematically reviewed and refined by second- and third-level agents, each employing distinct large language models and tailored strategies to detect unverified claims, incorporate explicit disclaimers, and clarify speculative content. Additionally, we introduce a set of novel Key Performance Indicators (KPIs) specifically designed to evaluate hallucination score levels. A dedicated fourth-level AI agent is employed to evaluate these KPIs, providing detailed assessments and ensuring accurate quantification of shifts in hallucination-related behaviors. A core component of this investigation is the use of the OVON (Open Voice Network) framework, which relies on universal NLP-based interfaces to transfer contextual information among agents. Through structured JSON messages, each agent communicates its assessment of the hallucination likelihood and the reasons underlying questionable content, thereby enabling the subsequent stage to refine the text without losing context. The results demonstrate that employing multiple specialized agents capable of interoperating with each other through NLP-based agentic frameworks can yield promising outcomes in hallucination mitigation, ultimately bolstering trust within the AI community.",
    "authors": [
      "Diego Gosmar",
      "Deborah A. Dahl"
    ],
    "year": 2025,
    "url": "https://www.semanticscholar.org/paper/543c141807e69f6613f29bcd820661945cc881d5"
  },
  {
    "title": "Embodied Reasoning with Self-Feedback",
    "abstract": "Large Language Models (LLMs) based on Transformer architecture have achieved remarkable success in Natural Language Processing (NLP). However, translating open-ended instructions into granular action plans for robotic systems remains a challenge. This paper proposes a self-supervised learning framework that enables an embodied multi-modal agent to comprehensively understand and perform tasks based on complex natural language interactions. The methodology focuses on an agentic workflow and self-refinement process, where the LLM actively engages in the task-solving process by generating its own problems, decomposing them, and refining the solutions through iterative self-feedback. The proposed methodology is evaluated on a maze navigation task, where an agent must extract sub-tasks from natural language instructions and navigate a grid while satisfying constraints. Experimental results demonstrate the effectiveness of the proposed approach in solving problems with multiple sub-tasks. Such capabilities could transform human-computer interaction and automated decision support.",
    "authors": [
      "Pranav Kak",
      "Sushma Jain"
    ],
    "year": 2024,
    "url": "https://www.semanticscholar.org/paper/4c2426f47d90839301899a28117c71fae3179b68"
  },
  {
    "title": "Can Agents Judge Systematic Reviews Like Humans? Evaluating SLRs with LLM-based Multi-Agent System",
    "abstract": "Systematic Literature Reviews (SLRs) are foundational to evidence-based research but remain labor-intensive and prone to inconsistency across disciplines. We present an LLM-based SLR evaluation copilot built on a Multi-Agent System (MAS) architecture to assist researchers in assessing the overall quality of the systematic literature reviews. The system automates protocol validation, methodological assessment, and topic relevance checks using a scholarly database. Unlike conventional single-agent methods, our design integrates a specialized agentic approach aligned with PRISMA guidelines to support more structured and interpretable evaluations. We conducted an initial study on five published SLRs from diverse domains, comparing system outputs to expert-annotated PRISMA scores, and observed 84% agreement. While early results are promising, this work represents a first step toward scalable and accurate NLP-driven systems for interdisciplinary workflows and reveals their capacity for rigorous, domain-agnostic knowledge aggregation to streamline the review process.",
    "authors": [
      "Abdullah M. Almasoud",
      "M. Naeem",
      "Ibrahim Ghaznavi",
      "Alaa Abd-alrazaq",
      "Aliya Tabassum",
      "Junaid Qadir"
    ],
    "year": 2025,
    "url": "https://www.semanticscholar.org/paper/11023a180caba404432213630ee4c0cc7426780f"
  },
  {
    "title": "Disambiguation in Conversational Question Answering in the Era of LLMs and Agents: A Survey",
    "abstract": "Ambiguity remains a fundamental challenge in Natural Language Processing (NLP) due to the inherent complexity and flexibility of human language. With the advent of Large Language Models (LLMs), addressing ambiguity has become even more critical due to their expanded capabilities and applications. In the context of Conversational Question Answering (CQA), this paper explores the definition, forms, and implications of ambiguity for language driven systems, particularly in the context of LLMs. We define key terms and concepts, categorize various disambiguation approaches enabled by LLMs, and provide a comparative analysis of their advantages and disadvantages. We also explore publicly available datasets for benchmarking ambiguity detection and resolution techniques and highlight their relevance for ongoing research. Finally, we identify open problems and future research directions, especially in agentic settings, proposing areas for further investigation. By offering a comprehensive review of current research on ambiguities and disambiguation with LLMs, we aim to contribute to the development of more robust and reliable LLM-based systems.",
    "authors": [
      "Md. Mehrab Tanjim",
      "Yeonjun In",
      "Xiang Chen",
      "Victor S. Bursztyn",
      "Ryan A. Rossi",
      "Sungchul Kim",
      "Guang-Jie Ren",
      "Vaishnavi Muppala",
      "Shun Jiang",
      "Yongsung Kim",
      "Chanyoung Park"
    ],
    "year": 2025,
    "url": "https://www.semanticscholar.org/paper/5217d9a8dd96be0c93cc2add7ff961453594ba30"
  }
]